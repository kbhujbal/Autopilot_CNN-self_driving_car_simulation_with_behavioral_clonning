# Deep Learning Model for Simulating Self Driving Car

**End-to-end Behavioral Cloning using NVIDIA's CNN Architecture**

![System Architecture](docs/system_architecture_detailed.png)

---

## Overview

This project implements an **end-to-end deep learning approach** for autonomous vehicle control using **Behavioral Cloning** in the Udacity Car Simulator. The convolutional neural network learns to predict steering angles by mimicking human driving behavior.

### Key Highlights

- Implements NVIDIA's proven end-to-end learning architecture for autonomous driving
- Multi-camera training with left, center, and right camera views
- Comprehensive data augmentation for generalization
- Successfully drives on Track 2 despite training only on Track 1

---

## Network Architecture

### NVIDIA CNN Architecture

![NVIDIA Network Architecture](docs/nvidia_architecture.png)

The model uses NVIDIA's proven architecture with 5 convolutional layers followed by 4 fully connected layers:

```
Input: 66√ó200√ó3 RGB Image
‚îú‚îÄ Normalization Layer (x/127.5 - 1.0)
‚îú‚îÄ Conv2D: 24 filters, 5√ó5, stride 2√ó2, ELU
‚îú‚îÄ Conv2D: 36 filters, 5√ó5, stride 2√ó2, ELU
‚îú‚îÄ Conv2D: 48 filters, 5√ó5, stride 2√ó2, ELU
‚îú‚îÄ Conv2D: 64 filters, 3√ó3, ELU
‚îú‚îÄ Conv2D: 64 filters, 3√ó3, ELU
‚îú‚îÄ Dropout (0.5)
‚îú‚îÄ Flatten (1164 neurons)
‚îú‚îÄ Dense: 100 neurons, ELU
‚îú‚îÄ Dense: 50 neurons, ELU
‚îú‚îÄ Dense: 10 neurons, ELU
‚îî‚îÄ Output: 1 neuron (Steering Angle)
```

**Total Parameters**: 348,219

---

## Installation

### Requirements

```bash
tensorflow>=2.8.0
keras>=2.8.0
opencv-python>=4.5.0
python-socketio>=5.5.0
eventlet>=0.33.0
pillow>=9.0.0
```

### Setup

1. **Clone the repository**:
```bash
git clone https://github.com/yourusername/AutoPilot.git
cd AutoPilot
```

2. **Install dependencies**:
```bash
pip install -r requirements.txt
```

3. **Download Udacity Car Simulator**:
   - [Linux](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58ae46bb_linux-sim/linux-sim.zip)
   - [macOS](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58ae4594_mac-sim.app/mac-sim.app.zip)
   - [Windows](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/58ae4419_windows-sim/windows-sim.zip)

---

## Dataset Collection

### Available Tracks

![Track 1](docs/track1.png)
*Track 1 - Simple track used for training*

![Track 2](docs/track2.png)
*Track 2 - Complex track for testing generalization*

### Collecting Data

1. Launch the simulator and select **TRAINING MODE**
2. Select **Track 1** and click **RECORD**
3. Drive smoothly for 2-3 laps (center lane + recovery maneuvers)
4. Include both clockwise and counter-clockwise laps

**Data Structure**:
- `driving_log.csv`: Contains image paths and steering angles
- `IMG/`: Three camera perspectives (left, center, right)

---

## Data Augmentation

![Implementation Architecture](docs/implementation_architecture.png)

Critical augmentation techniques for generalization:

1. **Crop & Resize**: Remove sky and hood to focus on road
2. **Horizontal Flip**: Eliminate directional bias
3. **Random Shift**: Simulate off-center driving
4. **Brightness Adjustment**: Handle different weather conditions
5. **Random Shadows**: Adapt to varying lighting
6. **Random Blur**: Simulate camera limitations

---

## Training

### Configuration

| Parameter | Value |
|-----------|-------|
| Input Shape | 66√ó200√ó3 |
| Learning Rate | 0.0001 |
| Epochs | 50 |
| Batch Size | 32 |
| Train/Val Split | 80/20 |
| Steering Correction | ¬±0.25 |
| Dropout | 0.5 |

### Run Training

```bash
python behavioral_cloning.py
```

The best model is automatically saved as `model_best.h5` based on validation loss.

---

## Testing in Autonomous Mode

1. Launch the simulator and select **AUTONOMOUS MODE**
2. Choose a track (Track 1 or Track 2)
3. Run the drive script:

```bash
python drive.py model_best.h5
```

**Optional: Set target speed**
```bash
python drive.py model_best.h5 --speed 15
```

---

## Results

![Loss Over Epochs](docs/loss_epochs.png)

### Performance Metrics

| Metric | Value |
|--------|-------|
| Final Training Loss | 0.0089 |
| Final Validation Loss | 0.0092 |
| Track 1 Performance | ‚úÖ Complete lap, smooth driving |
| Track 2 Performance | ‚úÖ Successful generalization |

The model successfully generalizes to Track 2 (unseen during training) thanks to comprehensive data augmentation and the robust NVIDIA architecture.

---

## Project Structure

```
AutoPilot/
‚îú‚îÄ‚îÄ behavioral_cloning.py      # Training script
‚îú‚îÄ‚îÄ drive.py                    # Autonomous driving script
‚îú‚îÄ‚îÄ requirements.txt            # Dependencies
‚îú‚îÄ‚îÄ driving_log.csv            # Training data log
‚îú‚îÄ‚îÄ IMG/                       # Training images
‚îú‚îÄ‚îÄ model_best.h5              # Trained model
‚îî‚îÄ‚îÄ docs/                      # Documentation images
```

---

## References

[1] **M. Bojarski et al., "End to End Learning for Self-Driving Cars"**, NVIDIA, 2016. [arXiv:1604.07316](https://arxiv.org/abs/1604.07316)

[2] A. Bhalla, M. S. Nikhila and P. Singh, "Simulation of Self-driving Car using Deep Learning", *3rd International Conference on Intelligent Sustainable Systems (ICISS)*, 2020.

[3] H. Fujiyoshi, T. Hirakawa, T. Yamashita, "Deep learning-based image recognition for autonomous driving", *IATSS Research, Volume 43, Issue 4*, 2019.

---

## Contact

**Kunal Bhujbal**
üìß kunalbhujbal41035@gmail.com
üè´ Vasantdada Patil Pratishthan's College of Engineering & Visual Arts, Mumbai

---

**Happy Autonomous Driving! üöóüí®**
